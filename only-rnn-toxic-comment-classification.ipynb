{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8076,"databundleVersionId":44219,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gensim\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom gensim.models import Word2Vec\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-12-05T01:50:33.350457Z","iopub.execute_input":"2023-12-05T01:50:33.350816Z","iopub.status.idle":"2023-12-05T01:50:40.779903Z","shell.execute_reply.started":"2023-12-05T01:50:33.350781Z","shell.execute_reply":"2023-12-05T01:50:40.779099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip /kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip","metadata":{"execution":{"iopub.status.busy":"2023-12-05T01:50:40.781596Z","iopub.execute_input":"2023-12-05T01:50:40.782104Z","iopub.status.idle":"2023-12-05T01:50:41.655044Z","shell.execute_reply.started":"2023-12-05T01:50:40.782076Z","shell.execute_reply":"2023-12-05T01:50:41.654226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"train.csv\")\ndata","metadata":{"execution":{"iopub.status.busy":"2023-12-05T01:50:41.656176Z","iopub.execute_input":"2023-12-05T01:50:41.656423Z","iopub.status.idle":"2023-12-05T01:50:42.842085Z","shell.execute_reply.started":"2023-12-05T01:50:41.656397Z","shell.execute_reply":"2023-12-05T01:50:42.841357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences = [text.split() for text in data['comment_text']]\nword2vec_model = Word2Vec(sentences, vector_size=300, window=5, min_count=1, workers=4)\n\nmax_len = 100\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(data['comment_text'])\ntext_seq = tokenizer.texts_to_sequences(data['comment_text'])\ntext_seq = pad_sequences(text_seq, maxlen=max_len)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T01:50:42.842919Z","iopub.execute_input":"2023-12-05T01:50:42.843179Z","iopub.status.idle":"2023-12-05T01:52:10.920186Z","shell.execute_reply.started":"2023-12-05T01:50:42.843153Z","shell.execute_reply":"2023-12-05T01:52:10.919180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab = tokenizer.word_index\nnum_tokens = len(vocab) + 2\nfinal_embed = np.zeros((num_tokens, 300))\n\nfor word, i in vocab.items():\n    if word in word2vec_model.wv:\n        final_embed[i] = word2vec_model.wv[word]\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T01:52:10.922650Z","iopub.execute_input":"2023-12-05T01:52:10.922995Z","iopub.status.idle":"2023-12-05T01:52:11.620366Z","shell.execute_reply.started":"2023-12-05T01:52:10.922965Z","shell.execute_reply":"2023-12-05T01:52:11.619479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare data and labels\ntoxicity_labels = data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\nX_train, X_val, y_train, y_val = train_test_split(text_seq, toxicity_labels, test_size=0.2, random_state=42)\n\n\n# TPU Configuration\ntry:\n    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()  # Detects the TPU\n    print(\"Running on TPU \", resolver.master())\n    tf.config.experimental_connect_to_cluster(resolver)\n    try:\n        tf.tpu.experimental.initialize_tpu_system(resolver)\n    except tf.errors.InvalidArgumentError:\n        print(\"TPU system already initialized. Continuing without reinitializing.\")\n    tpu_strategy = tf.distribute.experimental.TPUStrategy(resolver)\nexcept ValueError:\n    print(\"Could not detect TPU; defaulting to CPU or GPU.\")\n    tpu_strategy = tf.distribute.get_strategy()\n\n\nwith tpu_strategy.scope():\n    # LSTM Model\n    embed_input = keras.layers.Input(shape=(max_len,))\n    embed_layer = keras.layers.Embedding(num_tokens, 300, embeddings_initializer=keras.initializers.Constant(final_embed), trainable=False)(embed_input)\n    lstm_layer = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True))(embed_layer)\n    global_pool = keras.layers.GlobalMaxPool1D()(lstm_layer)\n    dense_layer = keras.layers.Dense(64, activation='relu')(global_pool)\n    output = keras.layers.Dense(6, activation='sigmoid')(dense_layer)\n\n    model = keras.Model(inputs=embed_input, outputs=output)\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Modified callback for tracking accuracy every 100 inputs\nclass BatchAccumulator(keras.callbacks.Callback):\n    def on_train_begin(self, logs=None):\n        self.batch_accs = []  # Store accuracies for each 100 inputs\n        self.temp_accs = []   # Temporary storage for accuracies\n        self.batch_counter = 0\n\n    def on_batch_end(self, batch, logs=None):\n        acc = logs.get('accuracy')\n        self.temp_accs.append(acc)\n        self.batch_counter += len(X_train[batch])  # Assuming batch is index, adjust accordingly\n\n        if self.batch_counter >= 100:  # Check if 100 inputs have been processed\n            avg_acc = np.mean(self.temp_accs)\n            self.batch_accs.append(avg_acc)\n            self.temp_accs = []  # Reset temporary storage\n            self.batch_counter = 0\n\nbatch_accumulator = BatchAccumulator()\n\n# Training the model\nhistory = model.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_val, y_val), callbacks=[batch_accumulator])\n\n# Plotting the accuracies at the end\nplt.plot(batch_accumulator.batch_accs)\nplt.title('Accuracy every 100 inputs')\nplt.xlabel('Batch (each represents 100 inputs)')\nplt.ylabel('Accuracy')\nplt.show()\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T01:56:34.939125Z","iopub.execute_input":"2023-12-05T01:56:34.940407Z","iopub.status.idle":"2023-12-05T01:59:12.554730Z","shell.execute_reply.started":"2023-12-05T01:56:34.940356Z","shell.execute_reply":"2023-12-05T01:59:12.553519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = text_seq\ny = data.drop(columns=['id','comment_text'],axis=1)\nprint(len(X),len(y))","metadata":{"execution":{"iopub.status.busy":"2023-12-05T01:54:21.223020Z","iopub.status.idle":"2023-12-05T01:54:21.223329Z","shell.execute_reply.started":"2023-12-05T01:54:21.223178Z","shell.execute_reply":"2023-12-05T01:54:21.223193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_X, test_X, train_y, test_y = train_test_split(X,y)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T01:54:21.224763Z","iopub.status.idle":"2023-12-05T01:54:21.225087Z","shell.execute_reply.started":"2023-12-05T01:54:21.224924Z","shell.execute_reply":"2023-12-05T01:54:21.224955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(train_X,train_y)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T01:54:21.226011Z","iopub.status.idle":"2023-12-05T01:54:21.226299Z","shell.execute_reply.started":"2023-12-05T01:54:21.226152Z","shell.execute_reply":"2023-12-05T01:54:21.226167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\npreds = model.predict(test_X)\nprint(\"ROC AUC Score\",roc_auc_score(test_y,preds))","metadata":{"execution":{"iopub.status.busy":"2023-12-05T01:54:21.229092Z","iopub.status.idle":"2023-12-05T01:54:21.229421Z","shell.execute_reply.started":"2023-12-05T01:54:21.229257Z","shell.execute_reply":"2023-12-05T01:54:21.229273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Assuming 'history.history['acc']' and 'history.history['val_acc']' are lists with length equal to the number of epochs\nnum_epochs = len(history.history['acc'])\n\nplt.plot(range(1, num_epochs + 1), history.history['acc'], label='Training Accuracy')\nplt.plot(range(1, num_epochs + 1), history.history['val_acc'], label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.xticks(range(1, num_epochs + 1))  # Set x-ticks to correspond to the epochs\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T01:54:21.230723Z","iopub.status.idle":"2023-12-05T01:54:21.231034Z","shell.execute_reply.started":"2023-12-05T01:54:21.230876Z","shell.execute_reply":"2023-12-05T01:54:21.230890Z"},"trusted":true},"execution_count":null,"outputs":[]}]}